{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"blog/gitops/","title":"How GitOps intertwines with Continuous Delivery","text":""},{"location":"blog/gitops/#introduction","title":"Introduction","text":"<p>In the ever-evolving landscape of Kubernetes orchestration, managing and deploying applications efficiently is crucial. Enter GitOps, a methodology that leverages the power of version control systems like Git to streamline operations, improve collaboration, and enhance the overall development lifecycle. In this blog post, we'll explore the core principles and best practices of GitOps.</p>"},{"location":"blog/gitops/#what-is-gitops","title":"What is GitOps?","text":"<p>GitOps is a set of practices that combine the benefits of declarative infrastructure as code and version control. The primary idea is to use Git repositories as a single source of truth for both application code and infrastructure configuration. This approach brings several advantages to the table, such as:</p> <ul> <li> <p>Declarative Configuration: Describe the desired state of your infrastructure and applications in a declarative manner, making it easier to understand and manage.</p> </li> <li> <p>Versioned Control: Leverage Git's version control capabilities to track changes, rollback to previous states, and collaborate seamlessly with teams.</p> </li> <li> <p>Continuous Delivery: Automate deployments by using Git as the trigger for CI/CD pipelines, ensuring a consistent and reproducible process.</p> </li> <li> <p>Operational Efficiency: GitOps minimizes manual interventions by relying on automated processes, reducing the risk of human errors and improving operational efficiency.</p> </li> </ul>"},{"location":"blog/gitops/#core-principles-of-gitops","title":"Core Principles of GitOps","text":""},{"location":"blog/gitops/#declarative-configuration","title":"Declarative Configuration","text":"<p>In GitOps, the entire infrastructure and application stack are defined declaratively. This means specifying the desired end state rather than prescribing a sequence of steps to reach that state. Tools like Kubernetes manifests, Helm charts, or custom YAML files serve as the declarative configuration, making it easy to understand and manage.</p>"},{"location":"blog/gitops/#version-control","title":"Version Control","text":"<p>Git is at the heart of GitOps. Every change, whether it's a modification to infrastructure configuration or an update to application code, is committed and versioned. This not only provides an audit trail but also enables rollbacks to previous states in case of issues, offering a safety net for operations.</p>"},{"location":"blog/gitops/#automation","title":"Automation","text":"<p>Automation is a key enabler of GitOps. Continuous Integration (CI) pipelines automatically build, test, and package applications, while Continuous Delivery (CD) pipelines use Git as a trigger to deploy changes to the target environment. This ensures consistency, repeatability, and traceability throughout the development lifecycle.</p>"},{"location":"blog/gitops/#observability","title":"Observability","text":"<p>GitOps encourages a robust observability practice. By integrating monitoring, logging, and alerting into the deployment process, teams gain insights into the health and performance of applications. This proactive approach allows for quick detection and resolution of issues.</p>"},{"location":"blog/gitops/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Infrastructure as Code (IaC): Treat infrastructure as code, using tools like Terraform or Kubernetes manifests. This ensures that changes are versioned, reviewed, and applied consistently.</p> </li> <li> <p>Git Workflow: Adopt a Git branching strategy that aligns with your release and deployment strategy. Consider feature branches for development, main branches for production releases, and tags for versioning.</p> </li> <li> <p>Automated Testing: Implement automated testing at various stages of the pipeline, including unit tests for application code and integration tests for infrastructure changes. This helps catch issues early in the development process.</p> </li> <li> <p>Secrets Management: Use tools or practices for secure storage and management of sensitive information such as API keys and passwords. Avoid storing secrets directly in the Git repository.</p> </li> <li> <p>Rollback Strategies: Plan and document rollback strategies in case of failed deployments. GitOps allows for easy rollbacks by reverting to a previous commit or tag.</p> </li> <li> <p>Immutable Infrastructure: Aim for immutable infrastructure by rebuilding and redeploying entire environments for updates. This ensures consistency and reduces the likelihood of configuration drift.</p> </li> </ol>"},{"location":"blog/gitops/#conclusion","title":"Conclusion","text":"<p>GitOps brings a paradigm shift to Kubernetes operations by promoting collaboration, automation, and version control. By leveraging Git as the source of truth, teams can enhance visibility, traceability, and reliability in their development and deployment processes. Embrace GitOps practices to navigate the complexities of Kubernetes with confidence and agility. Happy deploying!</p>"},{"location":"blog/platform-wars/","title":"PaaS vs DIY Kubernetes","text":"<p>In the current landscape of Kubernetes (k8s), there's a common misconception about whether Kubernetes is a Platform-as-a-Service (PaaS). Kubernetes' own documentation clarifies that it is not a traditional, all-inclusive PaaS system. However, this nuance doesn't make it a drawback; rather, it highlights an important distinction. As Kelsey Hightower puts it, \"Kubernetes is for people building platforms.\"</p>"},{"location":"blog/platform-wars/#kubernetes-overview","title":"Kubernetes Overview","text":"<p>Kubernetes is an open-source platform that offers shared services across clusters or nodes, such as scaling, load balancing, or monitoring. Unlike traditional PaaS systems, Kubernetes operates at the container level, providing developers with flexibility in choosing services, resources, and tools. If an application can be containerized, it can run on k8s.</p>"},{"location":"blog/platform-wars/#what-kubernetes-does","title":"What Kubernetes Does","text":"<ul> <li>Provides flexibility for app developers.</li> <li>Operates at the container level, allowing a diverse set of workflows.</li> <li>Does not limit the types of applications supported.</li> </ul>"},{"location":"blog/platform-wars/#what-kubernetes-doesnt-do","title":"What Kubernetes Doesn't Do","text":"<ul> <li>Does not provide services across applications, like databases or storage systems.</li> <li>Does not dictate a configuration language, leaving it open for diverse workflows.</li> </ul>"},{"location":"blog/platform-wars/#diy-kubernetes-pros","title":"DIY Kubernetes Pros","text":"<ul> <li>More out-of-the-box solutions available.</li> <li>More flexibility for app developers.</li> <li>Ease of containerized application migration.</li> </ul>"},{"location":"blog/platform-wars/#diy-kubernetes-cons","title":"DIY Kubernetes Cons","text":"<ul> <li>More required of app teams.</li> <li>More complex for simple applications.</li> <li>Challenges converting legacy applications.</li> <li>Flexibility drives compliance complexities.</li> </ul>"},{"location":"blog/platform-wars/#platform-as-a-service-paas","title":"Platform-as-a-Service (PaaS)","text":"<p>A good PaaS decouples application development and deployment from platform operations, allowing for increased focus on Day 2 operations, improved performance capabilities, and streamlined billing. Cloud Foundry is an example of an open-source PaaS project that, while no longer recommended, provides a frame of reference for what a PaaS should be.</p>"},{"location":"blog/platform-wars/#paas-pros","title":"PaaS Pros","text":"<ul> <li>Provides cross-app services.</li> <li>Decouples platform and app development.</li> <li>Ease of multi-cloud and hybrid approach.</li> <li>Structure and opinionation drive simplified controls compliance.</li> </ul>"},{"location":"blog/platform-wars/#paas-cons","title":"PaaS Cons","text":"<ul> <li>More upfront cost.</li> <li>Less flexibility for app teams.</li> <li>Larger infrastructure resource requirements.</li> </ul>"},{"location":"blog/platform-wars/#paas-or-k8s","title":"PaaS or K8s?","text":"<p>Choosing between PaaS and raw Kubernetes depends on organizational needs, infrastructure ownership, and technical competence. Over time, teams using raw k8s tend to build internal structures and opinionation, resembling an internal PaaS. The decision may involve weighing the cost-effectiveness of building in-house solutions versus adopting vendor solutions.</p>"},{"location":"blog/platform-wars/#considerations","title":"Considerations","text":"<ul> <li>Lock-in: In-house solutions also exhibit lock-in, and it's essential to evaluate various forms of lock-in.</li> <li>Costs: Upfront costs for PaaS may be higher, but it alleviates the burden on application developers.</li> <li>Flexibility: Kubernetes provides more flexibility but also more responsibility.</li> </ul> <p>There's no definitive answer; the choice depends on the organization's goals and capabilities. Whether PaaS or DIY Kubernetes, the key is to achieve the desired capabilities for successful application deployment.</p>"},{"location":"blog/users/","title":"Rise8 Continuous Delivery Approach","text":"<p>At Rise8, our mission revolves around achieving continuous delivery of impactful software that users love.</p>"},{"location":"blog/users/#continuous-delivery-the-feedback-loop","title":"Continuous Delivery: The Feedback Loop","text":"<p>Continuous delivery forms the feedback loop essential for achieving small batch sizes and iterating towards impactful software that brings joy to users. This process is carried out within a balanced team where the product manager practices lean enterprise, and UX focuses on user-centered design.</p>"},{"location":"blog/users/#continuous-delivery-first-approach","title":"Continuous Delivery First Approach","text":"<p>While numerous measures can be taken to mitigate risks, the ultimate validation point is the production environment. Hence, we adopt a continuous delivery first approach to establish learning feedback loops.</p>"},{"location":"blog/users/#leveraging-dora-insights","title":"Leveraging DORA Insights","text":"<p>We highly value the insights provided by the DORA (DevOps Research and Assessment) in identifying the key factors for achieving continuous delivery. We not only adhere to the DORA top five but also incorporate other crucial capabilities they've identified as contributors. This includes automated testing, clean code, loose coupling, monitoring, trunk-based development, and deployment automation, among others.</p>"},{"location":"blog/users/#high-compliance-spaces-ensuring-security-and-best-practices","title":"High Compliance Spaces: Ensuring Security and Best Practices","text":"<p>In high compliance spaces, we are pioneers in ensuring that deployment automation encompasses security compliance and adheres to release engineering best practices. This is particularly crucial due to the sensitivity and complexity of deployment environments.</p>"},{"location":"blog/users/#balancing-capability-and-security","title":"Balancing Capability and Security","text":"<p>Emphasizing both capability and security, we want to make it clear that continuous delivery doesn't necessitate accepting more risk; in fact, it actively reduces risk.</p>"},{"location":"blog/users/#effective-communication-for-stakeholder-buy-in","title":"Effective Communication for Stakeholder Buy-In","text":"<p>Our team possesses the expertise to communicate these principles effectively to both customers and stakeholders. This ensures the necessary buy-in to complete the feedback loops that unlock continuous delivery.</p>"},{"location":"general-engineering/practice-playbook/","title":"Engineering Practice Playbook","text":""},{"location":"general-engineering/practice-playbook/#preamble","title":"Preamble","text":"<p>This document contains our opinions on software development. We understand that it is not always possible to hold to some of these standards. We trust each of our engineer's autonomy to respond to any given situation.</p>"},{"location":"general-engineering/practice-playbook/#what-is-an-engineer","title":"What is an Engineer?","text":"<p>An engineer on a balanced team is responsible for the technical delivery of a product to the customer. They focus their time on building a secure, reliable, scalable, and maintainable product. The engineer brings a unique perspective to the team as they best understand the amount of work needed to build features. They also understand the impact technical debt can have on velocity. They work hand in hand with the product manager to buy down risks through backlog prioritization. The engineer also works with the designer to execute a design system and tease out technical pain points from the user. The engineer works with operations to optimize product delivery and support.</p> <p>\u201cA team management philosophy that has people with a variety of skills and perspectives that support each other towards a shared goal.\u201d - balancedteam.org</p>"},{"location":"general-engineering/practice-playbook/#foundation","title":"Foundation","text":"<p>Agile Manifesto Principles</p> <ol> <li>Our highest priority is to satisfy the customer through early and continuous delivery of valuable software.</li> <li>Welcome changing requirements, even late in development. Agile processes harness change for the customer\u2019s competitive advantage.</li> <li>Deliver working software frequently, from a couple of weeks to a couple of months, with a preference to the shorter timescale.</li> <li>Business people and developers must work together daily throughout the project.</li> <li>Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done.</li> <li>The most efficient and effective method of conveying information to and within a development team is face-to-face conversation.</li> <li>Working software is the primary measure of progress.</li> <li>Agile processes promote sustainable development. The sponsors, developers, and users should be able to maintain a constant pace indefinitely.</li> <li>Continuous attention to technical excellence and good design enhances agility.</li> <li>Simplicity \u2013 the art of maximizing the amount of work not done \u2013 is essential.</li> <li>The best architectures, requirements, and designs emerge from self-organizing teams.</li> <li>At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly.</li> </ol>"},{"location":"general-engineering/practice-playbook/#rise8-takes","title":"Rise8 Takes","text":"<ul> <li>Enablement is a primary skillset we practice here at Rise8. Not only building the product but helping build the team's skillset to continue product development.</li> <li>Pair engineers with projects they love.</li> <li>Offer opportunities for engineers to grow and expand.</li> <li>Trust allows agile teams to communicate quickly and respond rapidly to changes as they emerge. Without sufficient trust, team members can waste effort and energy hoarding information, forming cliques, dodging blame, and covering their tracks.</li> <li>Trust your team is making the best decisions with the information known at the moment, with or without your presence. You and your team have a common goal, there is more than one way to reach it.</li> <li>Technical facts and data overrule opinions and personal preferences.</li> <li>Use best practices and design patterns unless justified.</li> <li>Adheres to the team's code contract for styling.</li> </ul>"},{"location":"general-engineering/practice-playbook/#discovery","title":"Discovery","text":""},{"location":"general-engineering/practice-playbook/#discovery-and-framing","title":"Discovery and Framing","text":"<p>D&amp;F is a team effort where Product Manager and UI/UX roles will contribute significantly.</p>"},{"location":"general-engineering/practice-playbook/#build-vs-buy-analysis","title":"Build vs Buy Analysis","text":"<p>Engineers evaluate existing FOSS, Commercial, and Government Off the Shelf. Below are some helpful questions to get started in exploring your options and their potential return on investment.</p> <ul> <li>Is there an offering that sufficiently meets the team's requirements</li> <li>Build, operate, maintain, and upgrade cost Vs buy and licensing cost?</li> <li>Do we have the expertise to build?</li> <li>What is the learning curve/developer experience of the commercial products?</li> <li>Security requirements?</li> <li>Will new features be required, can they be added to the buy option?</li> <li>How much granular control of the system is necessary?</li> <li>Will the buy/FOSS option be maintained long term</li> <li>Is the offering well documented/provide a satisfactory user experience?</li> <li>Time to market?</li> </ul>"},{"location":"general-engineering/practice-playbook/#technology-stack","title":"Technology Stack","text":"<p>We choose the right Tech stack for the problem space. Here are a few things to consider when selecting tools and technologies</p> <ol> <li>Is training necessary? What is the learning curve? How much documentation is available? Is it good documentation?</li> <li>Are the skills and knowledge required common, or is the technology very niche?</li> <li>Is the technology mature enough to adopt?</li> <li>What are the costs?<ul> <li>compute cost of a low level language</li> <li>engineering wage difference between one language to another</li> <li>tooling</li> </ul> </li> <li>Is there support for the technology within the current continuous integration process?</li> <li>Can the technology be deployed to all environments?</li> <li>Can the technology be managed in all environments?</li> <li>Is the technology stack meeting security criteria and project constraints?</li> <li>Does the technology stack performance, reliability, and maintainability satisfy the product's requirements?</li> <li>Can the technology stack scale?</li> </ol>"},{"location":"general-engineering/practice-playbook/#building-an-mvp","title":"Building an MVP","text":"<p>Proof of Concept --&gt; Prototype --&gt; MVP</p>"},{"location":"general-engineering/practice-playbook/#proof-of-concept","title":"Proof of Concept","text":"<p>The Proof of Concept is for quick technical discovery, learning information, and empowering decision-making. It may be comprised of pseudo-code, code-fragments, and/or diagrams that depict how systems communicate or UIs interact. The outcome should validate &amp; verify the concept, and becomes the reference for the prototype.</p> <p>Should we use best practices when building a proof of concept?   - Not required, but encouraged   - Use as needed to explain the proposed concept</p>"},{"location":"general-engineering/practice-playbook/#prototype","title":"Prototype","text":"<p>The goal of a Prototype is to demo limited functionality to end users in an ideal/sandbox environment and help teams evaluate risk. This becomes a candidate for the initial MVP. Code should follow best practices unless it would be a severe time sink to implement.</p> <p>Should we use best practices when building a prototype? - Should try to use best practices, unless severe time sink</p> <p>What types of outcomes/information should the prototype produce? - Technical discovery - User traction/Customer feedback</p>"},{"location":"general-engineering/practice-playbook/#mvp","title":"MVP","text":"<p>An MVP builds on a Prototype by adding functionality, error handling, and integration with a production environment.</p> <p>What defines an MVP? - Full functionality - Meets all acceptance criteria</p> <p>Should we use best practices when building an MVP? - Best practices are standardized and required</p>"},{"location":"general-engineering/practice-playbook/#systems-design-and-architecture","title":"Systems Design and Architecture","text":""},{"location":"general-engineering/practice-playbook/#architecture","title":"Architecture","text":"<p>We will use <code>SPIKES</code> in the issue tracking system to document decisions that impact structure, non-functional characteristics, dependencies, interfaces, or construction techniques.  A Spike should be short and capture the specific context around the decision.  A Spike will have a Title, Status, Context, Decision, and Consequences section. Title Spikes with short Noun phrases such as \"SPIKE: Caching with Redis\". Status can be selected by the state of the issue in the issue tracking system. Context documents the technical and business forces at play; verbiage should be value neutral. Decision documents the why and how we choose to respond to the forces. Finally, Consequences documents any risks involved with the decision.</p> <p>It is good to keep a record of reversed decisions, and why it was reversed.  It is common for old failed decisions to resurface without historical knowledge in long-running projects.</p>"},{"location":"general-engineering/practice-playbook/#design-patterns-and-best-practices","title":"Design Patterns and Best Practices","text":"<p>We rely heavily on existing best practices and design patterns both for their proven capabilities and providing a common and well known means of solving a problem. Patterns and practices make it easier for engineers to move between projects.  However, there may be times we need to deviate such as, the new pattern leading to decreased readability, maintainability, scalability, and/or performance.  Note a performance issue in and of itself is not typically enough to justify a deviation.</p>"},{"location":"general-engineering/practice-playbook/#technical-debt","title":"Technical Debt","text":"<p>Technical debt can be defined as aspects of our code that will slow down future development. Debt can be intentional or unintentional but must be managed. Incurring too much technical debt can lead to a reduction in productivity, maintainability and testability which in turn leads to unhappy employees, decreased organizational performance, and lack of business outcomes. Engineers are responsible for making technical debt visible. Here are a few ways to mitigate and manage technical debt in your products:</p> <ol> <li>Keep a log of debt on your project for future conversations</li> <li>Discuss during backlog grooming</li> <li>Establish coding and documentation standards</li> <li>Familiarize yourself with common design &amp; architecture patterns</li> <li>Be aware of new technologies</li> </ol>"},{"location":"general-engineering/practice-playbook/#ceremonies","title":"Ceremonies","text":""},{"location":"general-engineering/practice-playbook/#iterative-planning-meeting-ipm","title":"Iterative Planning Meeting (IPM)","text":"<p>The IPM selects the work that will be done in the next cycle typically 1-2 week sprints. It is our recommendation to target work as follows. Target ranges</p> <ul> <li>30% - 50% Feature</li> <li>15% - 30% Innovation/Tech debt sometimes call chore</li> <li>5% - 20% Bugs</li> </ul> <p>When conducting an IPM the team will address: Acceptance Criteria Engineers can help the team by reviewing acceptance criteria before the sprint begins. The acceptance criteria should be clear and free of interpretation.</p> <p>Story Point Engineers can help the team by helping to point stories. They can help estimate the amount or complexity of the work. Since engineers understand the work involved to fulfill a requirement, they can ensure that stories are granular and right sized.</p> <p>Feature A Feature is something that provides new capabilities or improves end user experience. A Feature will often have a story that reads something like this. As a: xxx, I want: xxx, So That xxx. A feature should also have an acceptance criteria or definition of done.</p> <p>Innovation / Refactoring Innovation is proactive tech debt management.  Innovation work is time spent incorporating new libraries, patterns, or services to make the code base easier to maintain, read, secure, and scale, or add capabilities. Innovation work should be closely evaluated to ensure that it provides a return on investment. Avoid innovation for innovation\u2019s sake; there must be clearly definable advantage.</p> <p>Refactoring is an opportunity drive down existing technical debt, optimize, and re-architect the codebase. Refactoring keeps code simple, decoupled, easily read, and painlessly scaled. Engineers often complain about old programming languages as if the language is the root problem when the real problem is old messy spaghetti code.</p> <ol> <li>Knowledge sharing (both domain and technical knowledge)</li> <li>Immediate code reviews</li> <li>Improved interpersonal communication</li> <li>Reduction in code defects</li> </ol> <p>Bug Any work being done to correct unexpected behaviors or faults that are inconsistent with the desired coded intent.</p> <p>NOTE Security is a fundamental part of software development and as such can be characterized to fit in all three of the categories as needed.  However, you may to create your own category for security work; this is common in high compliance environments.</p>"},{"location":"general-engineering/practice-playbook/#standup","title":"Standup","text":"<p>A quick 10-15 min meeting typically held at the beginning of the day. Team members will give a few sentences on what they accomplished yesterday, are planning to do today, and any blockers they may have.  If greater detail is required, coordinate a discussion with the relevant team members post standup.</p>"},{"location":"general-engineering/practice-playbook/#retro","title":"Retro","text":"<p>A meeting to reflect on the past work cycle and identify what worked, what didn't and any actions needed to be taken going forward.  Release some stress while looking forward to the making the next work cycle better. This is also a good time to call out your team members on their accomplishments.</p>"},{"location":"general-engineering/practice-playbook/#pair-programming","title":"Pair Programming","text":"<p>We believe there is great value in paired programming and advocate it as the first option.  Pairing helps train inexperienced devs, allows for the propagation of tips and techniques, and provides accountability.</p> <p>Pair programming is a development technique where two developers author software using the same computer. In person, the computer is outfitted with two keyboards, two monitors and two mice. In a remote environment one user can share the screen with another via collaboration software such as Zoom and Live Share. There are two roles in pair programming:</p> <p>Driver: The person who is writing the code. Navigator: Helps the driver navigate the code development process. They can write code in the form of suggestions or corrections.</p> <p>Here are few helpful hints when pairing:</p> <ol> <li>Pairing can be tiring; take breaks often</li> <li>Rotate pairs regularly. Each person brings something unique to the table which will improve the codebase as a whole. Swapping pairs also drives both knowledge sharing and alignment across the team.</li> <li>Be open to new ideas and constructive criticism</li> <li>Sometimes pairing might not be the best approach. Feel free to solo when it makes sense. But remember, committed code requires a peer review.</li> </ol>"},{"location":"general-engineering/practice-playbook/#development","title":"Development","text":""},{"location":"general-engineering/practice-playbook/#test-driven-development","title":"Test Driven Development","text":"<p>Test Driven Development is a software development practice. The process starts with authoring a failing test and then implementing the functionality required for the test to succeed. Often times referred to as \u201cRed Green Refactor\u201d, it consists of three distinct steps (red-green-refactor):</p> <ol> <li>Author a failing test</li> <li>Author just enough code for test to pass</li> <li>Refactor</li> </ol>"},{"location":"general-engineering/practice-playbook/#code-review","title":"Code Review","text":"<p>The primary purpose of code review is to make sure that the overall code health of the project's codebase is improving over time, and a series of trade-offs have to be balanced.</p> <p>First, developers must be able to make progress on their tasks. If you never submit an improvement to the codebase, then the codebase never improves. Also, if a reviewer makes it very difficult for any change to go in, developers are disincentivised to improve in the future.</p> <p>Second, the reviewer must ensure that each merge request is of such a quality that their codebase's overall health is not decreasing as time goes on. This can be tricky because codebases degrade through small decreases in code health over time, especially when a team is under significant time constraints and feel that they have to take shortcuts to accomplish their goals.</p> <p>A reviewer has ownership and responsibility for the code they are reviewing. They want to ensure that the codebase stays consistent and maintainable.</p> <p>Thus, we get the following rule as the standard we expect in code reviews:</p> <p>In general, reviewers should favor approving a merge request once it is in a state where it improves the overall code health of the system being worked on, even if the merge request isn't perfect.</p> <p>There are limitations to this, of course. For example, if a merge request adds a feature that the reviewer doesn't want in their system, then the reviewer can certainly deny approval even if the code is well-designed.</p> <p>A key point here is that there is no such thing as \"perfect\" code\u2014there is only better code. Reviewers should not require the author to polish every tiny piece of a merge request before approving. Instead, the reviewer should balance out the need to make forward progress compared to the importance of the changes they are suggesting. Instead of seeking perfection, what a reviewer should seek is continuous improvement. A merge request that improves the maintainability, readability and understandability of the system shouldn't be delayed because it isn't \"perfect.\"</p> <p>Reviewers should always feel free to leave comments expressing that something could be better, but if it's not very important, prefix it with something like \"Nit: \"to let the author know that it's just a point of polish that they could choose to ignore (Nit means nit-pick).</p> <p>Note: Nothing in this document justifies checking in merge requests that worsen the system's overall code health. The only time you would do that would be in an emergency.</p> <ul> <li>Aspects of software design are seldom a pure style issue or just a personal preference. They are based on underlying principles and should be weighed on those principles, not simply by subjective opinion. Sometimes there are a few valid options. If the author can demonstrate (either through data or based on solid engineering principles) that several approaches are equally good, the reviewer should accept the author's preference. Otherwise, the choice is dictated by standard principles of software design.</li> <li>If no other rule applies, then the reviewer may ask the author to be consistent with the current codebase, as long as that doesn't worsen the system's overall code health.</li> <li>On matters of style, the style guide is the absolute authority. Any purely style point (whitespace, etc.) not in the style guide is a personal preference. The style should be consistent with what is there. If there is no previous style, accept the author's style.</li> </ul> <p>An opportunity for sharing knowledge Code reviews can be an essential function for teaching developers something new about a language, a framework, or general software design principles. It's always OK to leave comments that help a developer learn something new. Sharing knowledge is part of improving the code health of a system over time. Just keep in mind that if your comment is purely educational but not critical to meeting the standards described in this document, prefix it with \"Nit:\" or otherwise indicate that the author doesn't need to resolve it in this merge request.</p> <p>Resolving Conflicts In any conflict on a code review, the first step should always be for the developer and reviewer to reach an agreement.</p> <p>When coming to consensus becomes especially difficult, it can help to have a face-to-face meeting or a video conference between the reviewer and the author, instead of just trying to resolve the conflict through code review comments. (If you do this, though, make sure to record the discussion results as a comment on the merge request for future readers.)</p> <p>If that doesn't resolve the situation, the most common way to resolve it would be to escalate. Often the escalation path is to a broader team discussion, having a Technical Lead weigh in, asking for a decision from a maintainer of the code, or asking an Eng Manager to help.</p> <p>Don't let a merge request sit around because the author and the reviewer can't agree.</p> <p>This section was derived, with modifications, from Google Engineering Practices Documentation</p>"},{"location":"general-engineering/practice-playbook/#git-ops","title":"Git ops","text":"<p>Git is today's standard for source control.</p>"},{"location":"general-engineering/practice-playbook/#hooks","title":"HOOKS","text":"<p>We strongly encourage the use of commit hooks to further ensure code quality. These hooks can range from enforcing commit formats to running unit tests and may be left up to the team to decide.</p>"},{"location":"general-engineering/practice-playbook/#commit-messages","title":"COMMIT MESSAGES","text":"<p>Commit messages should be a brief, concise description in imperative tense of what the commit adds, with the appropriate authors (alternating authors or using tools such as git with .git-together), and the ID of the corresponding story. Using industry standards such as Conventional Commits are not required but teams may choose to follow any given industry standard.</p>"},{"location":"general-engineering/practice-playbook/#merge-request-comments","title":"MERGE REQUEST COMMENTS","text":"<p>We encourage comments/suggestions/questions/discussion/etc. on MR per our belief in strong opinions loosely held &gt;&gt; better resulting code</p>"},{"location":"general-engineering/practice-playbook/#rebase","title":"REBASE","text":"<p>We encourage squashing and rebasing to preserve the cleanliness and readability of the git history on the master branch. This should only be performed by an engineer that understands the rebasing process in order to avoid causing irreparable damage to the master branch. If done correctly, there should be no explicit merge commits.</p> <p>NOTE: Certain technologies (i.e. GitLab) default behavior creates merge commits. This can be changed.</p>"},{"location":"general-engineering/practice-playbook/#branching","title":"BRANCHING","text":"<p>Trunk based or short-lived feature branching is preferred.</p> <p>Branch naming should be clear and concise. We recommend the convention of including the story ID followed by a few words for the branch's purpose, using dashes (-) as the delimiter.</p> <p>Cleanup/remove branches post merge completion. Developers should be wary and not have too many inactive/stale branches linger. Abandoned branches should be removed to avoid Git pollution.</p>"},{"location":"general-engineering/practice-playbook/#cicd-pipeline","title":"CI/CD Pipeline","text":"<p>Continuous Integration We believe CI begins at the local development env. This includes the tools to run automated tests, linting, and other checks on branches BEFORE you merge up.</p> <p>We believe CI is non-negotiable and must begin at the initial conception of development to ensure comprehensive software security, testing, and fast feedback on the main branch health. Furthermore, it empowers the ability of the team to hold to agile practices.</p> <p>CI stages should include at a minimum - linting - unit tests - static code analysis - dependency scans</p> <p>Continuous Delivery We believe that any merge to main should be able to deploy to production and main should always be deployable. Merges should be self-contained and not dependant upon another branch.</p>"},{"location":"general-engineering/practice-playbook/#testing","title":"Testing","text":"<p>Building testing into our products provides us the confidence that we need to quickly deliver new features without the fear of breaking our products. The test pyramid depicts the types of test we can author along with the general distribution.</p>"},{"location":"general-engineering/practice-playbook/#unit","title":"Unit","text":"<p>The unit test is designed to test a small, singular component/function/method. Target the public methods of your classes, private and protected methods are part of the public unit. The tests are easy to author and maintain, and are fast to run. Unit Tests represent the largest portion of tests within the code.</p>"},{"location":"general-engineering/practice-playbook/#contract-testing","title":"Contract Testing","text":"<p>TDD for microservice architecture contracts are written on what will be consumed and then consumers and producers are tested against these contracts.  Eliminates the need for test environments that have all services running and at a specific version.</p>"},{"location":"general-engineering/practice-playbook/#integration","title":"Integration","text":"<p>The integration test is designed to test between components. A typical example might be integrating with a database or a provided REST service. Integration tests require that you stand up not only your product but also the components with which you integrate. For this reason, they require more time and effort than unit tests. They are often times the second most frequently used test.</p>"},{"location":"general-engineering/practice-playbook/#end-to-end-e2e","title":"End to End (E2E)","text":"<p>The end-to-end test is designed to test through your stack starting at the front end. The tests require the most time and effort to write and maintain. For this reason, they often represent the smallest portion of your tests.</p> <p>For further reading take a look at the list of curated resources</p> <ul> <li>https://martinfowler.com/articles/practical-test-pyramid.html</li> </ul>"},{"location":"general-engineering/practice-playbook/#operating-apps","title":"Operating Apps","text":""},{"location":"general-engineering/practice-playbook/#logging-operating-apps","title":"Logging (Operating apps)","text":"<p>As you ship your application into production you want to make sure that your logs can be processed and aggregated easily. Designing your application in this fashion will allow the platform to treat all application logs the same. Additionally, it allows for providing a base set of services your organization will need to support and operate your application. A few examples include, access to logs for debugging as well as setting up alerts for monitoring. The standard practice is to write log entries to stdout. For further information, check out the  logs section on 12factor.net</p>"},{"location":"general-engineering/practice-playbook/#configuration-design","title":"Configuration (Design)","text":"<p>Your application will exist in numerous environments including development, staging and production. For this reason, it is important that your application can be configured easily. Keep in mind that your application is likely to end up on a platform like Kubernetes where managing the lifecycle of an application is significant. The standard practice is to expose configuration via granular environment variables. The configuration defines a contract with the tools that manages your application\u2019s lifetime. For further information, check out the config section on 12factor.net</p>"},{"location":"general-engineering/practice-playbook/#backing-services-design","title":"Backing Services (Design)","text":"<p>As you build out your application, there will be a set of services you wish to consume. You should consider what services are needed and if they are provided as part of the platform offering. Configuring these services is as simple as adding environment variables to your configuration (see above). Listed below are common services:</p> <ol> <li>Identity Management (ie Keycloak)</li> <li>Databases (ie Relational, NoSQL)</li> <li>Storage (ie S3, Minio, Volumes)</li> <li>Message Queues (ie RabbitMQ, Kafka)</li> <li>Email (ie SMTP)</li> </ol>"},{"location":"general-engineering/practice-playbook/#monitoring-operating","title":"Monitoring (Operating)","text":"<p>Monitoring your application will help you be successful. Monitoring can help you understand how your application is being used and by whom. Monitoring can help you understand whether your application is functioning. When you start building your application consider the following:</p> <ol> <li>Are health endpoints available in my application? What engineering aspects should be part of the health endpoint? How are the health endpoints monitored?</li> <li>Are there important product metrics to capture? Are there any technologies available to support metrics collection (ie Elasticsearch, Kibana, Grafana)?</li> <li>Are there technologies available to support alerting?</li> </ol>"},{"location":"general-engineering/practice-playbook/#additional-resources","title":"Additional Resources","text":"<ul> <li>https://12factor.net</li> </ul>"},{"location":"general-engineering/practice-playbook/#recommended-reads","title":"Recommended Reads","text":"<ul> <li>Clean Code by Robert C. Martin</li> <li>Composing Software by Eric Elliot</li> <li>Design Patterns by Gang of Four</li> <li>Pragmatic Programmer</li> <li>Event-Driven Microservices</li> </ul>"},{"location":"general-engineering/practice-playbook/#notes","title":"Notes","text":"<ol> <li> <p>Accelerate\u00a0\u21a9</p> </li> <li> <p>Accelerate\u00a0\u21a9</p> </li> </ol>"},{"location":"platform-engineering/methodologies/general-best-practices/","title":"Platform Playbook","text":"<p>Platform engineering involves designing, building, and maintaining the infrastructure and tools that enable software development and deployment. Adopting best practices in platform engineering ensures a stable, scalable, and efficient environment for development teams. Here are some detailed best practices:</p>"},{"location":"platform-engineering/methodologies/general-best-practices/#1-infrastructure-as-code-iac","title":"1. Infrastructure as Code (IaC):","text":"<ul> <li>Use IaC tools like Terraform or Ansible to define and manage infrastructure.</li> <li>Version control your IaC scripts to track changes and enable collaboration.</li> <li>Implement a modular structure for IaC to promote reusability and maintainability.</li> </ul>"},{"location":"platform-engineering/methodologies/general-best-practices/#2-containerization","title":"2. Containerization:","text":"<ul> <li>Containerize applications using technologies like Docker for consistency across environments.</li> <li>Use orchestration tools such as Kubernetes for automated deployment, scaling, and management of containers.</li> <li>Optimize container images for size and security.</li> </ul>"},{"location":"platform-engineering/methodologies/general-best-practices/#3-continuous-integration-and-continuous-deployment-cicd","title":"3. Continuous Integration and Continuous Deployment (CI/CD):","text":"<ul> <li>Implement CI/CD pipelines to automate testing, building, and deployment processes.</li> <li>Include automated testing at various stages to catch issues early.</li> <li>Use feature flags to enable gradual and safe feature rollouts.</li> </ul>"},{"location":"platform-engineering/methodologies/general-best-practices/#4-monitoring-and-logging","title":"4. Monitoring and Logging:","text":"<ul> <li>Establish comprehensive monitoring for applications and infrastructure.</li> <li>Utilize centralized logging to gather and analyze logs for troubleshooting.</li> <li>Implement alerting systems to detect and respond to issues proactively.</li> </ul>"},{"location":"platform-engineering/methodologies/general-best-practices/#5-scalability","title":"5. Scalability:","text":"<ul> <li>Design systems to scale horizontally by adding more instances.</li> <li>Use auto-scaling groups to automatically adjust resources based on demand.</li> <li>Regularly perform load testing to identify potential bottlenecks.</li> </ul>"},{"location":"platform-engineering/methodologies/general-best-practices/#6-security","title":"6. Security:","text":"<ul> <li>Implement security best practices for infrastructure and applications.</li> <li>Regularly update dependencies and conduct security audits.</li> <li>Enforce least privilege access controls and regularly rotate credentials.</li> </ul>"},{"location":"platform-engineering/methodologies/general-best-practices/#7-documentation","title":"7. Documentation:","text":"<ul> <li>Maintain comprehensive documentation for infrastructure, deployment processes, and configurations.</li> <li>Keep documentation up-to-date to facilitate knowledge sharing and onboarding.</li> </ul>"},{"location":"platform-engineering/methodologies/general-best-practices/#8-high-availability-ha","title":"8. High Availability (HA):","text":"<ul> <li>Design systems with redundancy to ensure availability in case of failures.</li> <li>Distribute applications across multiple availability zones or regions.</li> <li>Test and simulate failure scenarios to validate HA configurations.</li> </ul>"},{"location":"platform-engineering/methodologies/general-best-practices/#9-collaboration-and-communication","title":"9. Collaboration and Communication:","text":"<ul> <li>Foster collaboration between development, operations, and other teams.</li> <li>Use collaboration tools and platforms for effective communication.</li> <li>Conduct regular cross-functional meetings to align goals and address challenges.</li> </ul>"},{"location":"platform-engineering/methodologies/general-best-practices/#10-performance-optimization","title":"10. Performance Optimization:","text":"<ul> <li>Regularly assess and optimize the performance of both infrastructure and applications.</li> <li>Use caching mechanisms, content delivery networks (CDNs), and other optimization techniques.</li> <li>Monitor and optimize database queries for efficiency.</li> </ul> <p>By adhering to these platform engineering best practices, teams can create a robust and efficient environment that supports the continuous delivery of high-quality software.</p>"},{"location":"platform-engineering/practicals/argocd-examples/","title":"ArgoCD: Application of ApplicationSets","text":"<p>An application of ApplicationSets in ArgoCD is to efficiently manage and deploy similar applications or configurations across multiple clusters or namespaces. Here's a specific example to illustrate the application of ApplicationSets:</p>"},{"location":"platform-engineering/practicals/argocd-examples/#scenario","title":"Scenario","text":"<p>Imagine you have a microservices architecture, and you need to deploy the same application stack to multiple namespaces within a Kubernetes cluster. Each namespace may represent a different environment, such as development, testing, and production.</p>"},{"location":"platform-engineering/practicals/argocd-examples/#applicationsets-implementation","title":"ApplicationSets Implementation","text":""},{"location":"platform-engineering/practicals/argocd-examples/#1-generator","title":"1. Generator:","text":"<ul> <li>Define a generator that generates application names, namespaces, and other parameters based on a specific pattern or set of rules.</li> </ul> <pre><code>generators:\n- list:\n    elements:\n    - name: my-app-{{randAlphaNum 5}}\n      namespace: {{item}}\n</code></pre>"},{"location":"platform-engineering/practicals/argocd-examples/#2-template","title":"2. Template:","text":"<ul> <li>Create a template specifying the common configuration for your application. This includes the source repository, target revision, and destination settings.</li> </ul> <pre><code>template:\n   metadata:\n      labels:\n         app.kubernetes.io/name: '{{.name}}'\n   spec:\n      project: default\n      source:\n         repoURL: 'https://github.com/example/repo'\n         targetRevision: HEAD\n      destination:\n         namespace: '{{.namespace}}'\n         server: 'https://kubernetes.default.svc'\n</code></pre>"},{"location":"platform-engineering/practicals/argocd-examples/#3-applicationset-manifest","title":"3. ApplicationSet Manifest:","text":"<ul> <li>Apply the ApplicationSet manifest that defines the generators and template.</li> </ul> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n   name: my-app-set\nspec:\n   generators:\n   - list:\n         elements:\n         - dev\n         - test\n         - prod\ntemplate:\n   metadata:\n      labels:\n      app.kubernetes.io/part-of: my-app-set\n   spec:\n      project: default\n      source:\n      repoURL: 'https://github.com/example/repo'\n      targetRevision: HEAD\n      destination:\n      server: 'https://kubernetes.default.svc'\n</code></pre>"},{"location":"platform-engineering/practicals/argocd-examples/#result","title":"Result","text":"<ul> <li>ArgoCD will dynamically generate and deploy three instances of the application, each to a different namespace (dev, test, prod).</li> <li>The common configuration specified in the template ensures consistency across all instances.</li> <li>Changes made to the ApplicationSet manifest automatically reflect in the generated applications, allowing for easy scaling and maintenance.</li> </ul>"},{"location":"platform-engineering/practicals/argocd-examples/#use-cases","title":"Use Cases","text":""},{"location":"platform-engineering/practicals/argocd-examples/#1-scalable-deployments","title":"1. Scalable Deployments:","text":"<ul> <li>Easily scale deployments across different namespaces or clusters without manually managing each application.</li> </ul>"},{"location":"platform-engineering/practicals/argocd-examples/#2-environment-isolation","title":"2. Environment Isolation:","text":"<ul> <li>Isolate configurations for different environments, ensuring separation and consistency.</li> </ul>"},{"location":"platform-engineering/practicals/argocd-examples/#3-efficient-management","title":"3. Efficient Management:","text":"<ul> <li>Streamline the deployment of similar applications with minimal manual intervention.</li> </ul> <p>ApplicationSets in ArgoCD provide a powerful mechanism for handling repetitive deployment scenarios and managing configurations at scale.</p>"},{"location":"software-engineering/practicals/create-api-example/","title":"Writing a Simple API with Flask (Python)","text":""},{"location":"software-engineering/practicals/create-api-example/#introduction","title":"Introduction","text":"<p>In this tutorial, we'll walk through the process of creating a simple RESTful API using Python and the Flask web framework. Flask is a lightweight and easy-to-use framework for building web applications, including APIs.</p>"},{"location":"software-engineering/practicals/create-api-example/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the following installed:</p> <ul> <li>Python (Python Official Website)</li> <li>Flask (<code>pip install Flask</code>)</li> </ul>"},{"location":"software-engineering/practicals/create-api-example/#step-1-setting-up-the-project","title":"Step 1: Setting Up the Project","text":"<p>Create a new directory for your project and navigate into it.</p> <pre><code>mkdir flask-api-tutorial\ncd flask-api-tutorial\n</code></pre>"},{"location":"software-engineering/practicals/create-api-example/#step-2-creating-a-virtual-environment","title":"Step 2: Creating a Virtual Environment","text":"<p>It's good practice to use a virtual environment to isolate your project's dependencies. Create a virtual environment using the following commands:</p> <pre><code>python -m venv venv\n# On Windows: python -m venv venv\nActivate the virtual environment:\n</code></pre> <pre><code># On macOS/Linux\nsource venv/bin/activate\n# On Windows\nvenv\\Scripts\\activate\nThis step ensures that your project has a dedicated environment for its dependencies, minimizing conflicts and ensuring consistency across different projects.\n</code></pre>"},{"location":"software-engineering/practicals/create-api-example/#step-3-installing-flask","title":"Step 3: Installing Flask","text":"<p>Install Flask within the virtual environment:</p> <pre><code>pip install Flask\n</code></pre>"},{"location":"software-engineering/practicals/create-api-example/#step-4-writing-the-api-code","title":"Step 4: Writing the API Code","text":"<p>Create a file named app.py in your project directory and open it in a text editor. Add the following code:</p> <pre><code>from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/api', methods=['GET'])\ndef get_data():\n    data = {'message': 'Hello, API!'}\n    return jsonify(data)\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre> <p>This code sets up a basic Flask application with a single endpoint (/api) that returns a JSON response.</p>"},{"location":"software-engineering/practicals/create-api-example/#step-5-running-the-api","title":"Step 5: Running the API","text":"<p>In the terminal, run the Flask application:</p> <pre><code>python app.py\nVisit http://127.0.0.1:5000/api in your browser or use a tool like curl or Postman to make a GET request.\n</code></pre> <pre><code>curl http://127.0.0.1:5000/api\nYou should receive a JSON response: {\"message\": \"Hello, API!\"}\n</code></pre>"},{"location":"software-engineering/practicals/create-api-example/#conclusion","title":"Conclusion","text":"<p>Congratulations! You've successfully created a simple API using Flask. This is just a starting point, and you can expand and enhance your API by adding more routes, handling different HTTP methods, and integrating with databases.</p> <p>Explore Flask's documentation (Flask Documentation) for more advanced features and best practices.</p> <p>Feel free to adapt this tutorial to other frameworks or languages as needed.</p>"}]}